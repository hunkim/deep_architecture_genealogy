Neural Net Arch Genealogy
	Reinforcement Learning Algorithms
		[A3C, '16.02.06](https://arxiv.org/abs/1602.01783)
		[DARLA, '17.07.26](https://arxiv.org/pdf/1707.08475.pdf)
		[ACTKR, '17.08.17](https://arxiv.org/pdf/1708.05144.pdf)
		[c51, '17.10.27](https://arxiv.org/pdf/1710.10044.pdf)
	CNN
		[AlexNet, '12.12](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
		[VggNet, '14.09](https://arxiv.org/pdf/1409.1556.pdf)
		[GoogLeNet, '14.09](https://arxiv.org/abs/1409.4842)
		[ResNet, '15.12](https://arxiv.org/pdf/1512.03385v1.pdf)
		[DenseNet, '16.08](https://arxiv.org/pdf/1608.06993.pdf)
		[SENet: Squeeze-and-Excitation Networks, '17.09](https://arxiv.org/abs/1709.01507)
		Object Detection
			[R-CNN](https://arxiv.org/pdf/1311.2524.pdf)
			[Fast R-CNN](https://arxiv.org/pdf/1504.08083.pdf)
			[Faster R-CNN](https://arxiv.org/pdf/1506.01497.pdf)
			[Mask R-CNN](https://arxiv.org/pdf/1703.06870.pdf)
			[YOLO](https://arxiv.org/pdf/1506.02640.pdf)
			[SSD](https://arxiv.org/pdf/1512.02325.pdf)
			[R-FCN](https://arxiv.org/pdf/1605.06409.pdf)
		Semantic Segmentation
			[FCN](https://arxiv.org/pdf/1411.4038.pdf)
			[DeconvNet](https://arxiv.org/pdf/1505.04366.pdf)
			[DeepLab](https://arxiv.org/pdf/1606.00915.pdf)
			[U-Net](https://arxiv.org/pdf/1505.04597.pdf)
		Super-resolution
			[MemNet](https://arxiv.org/abs/1708.02209)
			[FSRCNN](https://arxiv.org/1608.00367)
			[SRCNN](https://arxiv.org/abs/1501.00092)
			[VDSR](https://arxiv.org/abs/1511.04587)
			[DRCN](https://arxiv.org/abs/1511.04491)
			[LabSRN](https://arxiv.org/abs/1704.03915)
			[EDSR](https://arxiv.org/abs/1707.02921)
		TTS
			[Wavenet, '16.09.12](https://arxiv.org/abs/1609.03499)
	Generative Models
		Autoregressive models
			[MADE, '15.02.12](https://arxiv.org/pdf/1502.03509.pdf)
			[PixelRNN, '16.01.25](https://arxiv.org/pdf/1601.06759.pdf)
			[NADE, '16.05.07](https://arxiv.org/pdf/1605.02226.pdf)
			[PixelCNN, '16.06.16](https://arxiv.org/pdf/1606.05328.pdf)
			[PixelCNN++, '17.01.19](https://arxiv.org/pdf/1701.05517.pdf)
		Latent variable models
			[VAE, '13.12.20](https://arxiv.org/pdf/1312.6114.pdf)
				[CVAE, '14.06.20](https://arxiv.org/pdf/1406.5298.pdf)
				[AAE, '15.11.18](https://arxiv.org/pdf/1511.05644.pdf)
				[AVB, '17.01.17](https://arxiv.org/pdf/1701.04722.pdf)
				[VQ-VAE, '17.11.2](https://arxiv.org/abs/1711.00937)
			[GAN, '14.06.10](https://arxiv.org/pdf/1406.2661.pdf)
				Variants
					[CGAN, '14.11.06](https://arxiv.org/pdf/1411.1784.pdf)
					[DCGAN, '15.11.19](https://arxiv.org/pdf/1511.06434.pdf)
					[infoGAN, '16.06.12](https://arxiv.org/pdf/1606.03657.pdf)
					[EBGAN, '16.09.11](https://arxiv.org/pdf/1609.03126.pdf)
					[ACGAN, '16.10.30](https://arxiv.org/pdf/1610.09585.pdf)
					[WGAN, '17.01.26](https://arxiv.org/pdf/1701.07875.pdf)
					[BEGAN, '17.02.27](https://arxiv.org/pdf/1702.08431.pdf)
					[WGAN-GP, '17.03.31](https://arxiv.org/pdf/1704.00028.pdf)
					[TripleGAN, '17.03.07](https://arxiv.org/pdf/1703.02291.pdf)
				Applications
					[Pix2Pix, '16.11.21](https://arxiv.org/pdf/1611.07004v1.pdf)
					[PPGN, '16.11.30](https://arxiv.org/pdf/1612.00005.pdf)
					[StackGAN, '16.12.10](https://arxiv.org/pdf/1612.03242.pdf)
	RNN
		[LSTM, '97.11](http://www.mitpressjournals.org/doi/10.1162/neco.1997.9.8.1735)
		[GRU, 14.11](https://arxiv.org/abs/1412.3555)
		[ACT: Adaptive Computation Time, '17.05](https://arxiv.org/abs/1603.08983)
		[S2S: RNN Encoder-Decoder, '14.06](https://arxiv.org/abs/1406.1078)
			[Attention: Jointly Learning to Align, '14.09](https://arxiv.org/abs/1409.0473)
				[Effective Approaches to Attention, Luong et al. '15.08](https://arxiv.org/abs/1508.04025)
				[DCN: Dynamic Coattention Networks, '16.08](https://arxiv.org/abs/1611.01604), [DCN+, '17.08](https://arxiv.org/abs/1711.00106)
	Self-attention
		NLP
			[Transformer: Attention Is All You Need, '17.06](https://arxiv.org/abs/1706.03762)
			[GPT1: Improving Language Understanding by Generative Pre-Training, '18.06](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)
			[BERT: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, '18.10](https://arxiv.org/abs/1810.04805)
			[GPT2: Language Models are Unsupervised Multitask Learners, '19.01](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)
			[GPT3: Language Models are Few-Shot Learners, '20.05](https://arxiv.org/abs/2005.14165)
		Vision
			[Image-GPT: Generative Pretraining from Pixels, '20.06](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf)			
			[Vision transformer: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale, '20.09](https://arxiv.org/abs/2010.11929)
			[DeiT: Training data-efficient image transformers & distillation through attention, '20.12](https://arxiv.org/abs/2012.12877)
		Speech
		Multimodal
			[DALL-E, '21.01](https://openai.com/blog/dall-e/)
			[CLIP: Learning Transferable Visual Models From Natural Language Supervision](https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf)
			
	[Capsule Net, '17.10](https://arxiv.org/abs/1710.09829)
	Memory Networks
		Neural Programming
			[Neural Turing Machine,'14.10](https://arxiv.org/pdf/1410.5401.pdf)
			[Neural Random-Access Machines,'16.02](https://arxiv.org/pdf/1511.06392.pdf)
			[Hierarchical Attentive Memory, '16.02](https://arxiv.org/abs/1602.03218)
			[Neural GPUs Learn Algorithms, '16.03](https://arxiv.org/pdf/1511.08228.pdf)
			[Neural Programmer,'16.08](https://arxiv.org/pdf/1511.04834.pdf)
			[Neural Module Networks, '16.06](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Andreas_Neural_Module_Networks_CVPR_2016_paper.html)
			[Hybrid Computing, '16.10](https://www.nature.com/nature/journal/v538/n7626/full/nature20101.html)
		[Memory Networks,'14.10](https://arxiv.org/pdf/1410.3916.pdf)
		[End-to-End Memory Network,'15.03](https://arxiv.org/pdf/1503.08895.pdf)
		[DMN: Dynamic Memory Network, '16.03](https://arxiv.org/pdf/1506.07285.pdf), [DMN+, '16.04 ](https://arxiv.org/pdf/1603.01417.pdf) 
